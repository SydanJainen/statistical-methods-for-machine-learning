{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '../data/raw/dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X, y, alpha):\n",
    "    X_bias = pd.concat([pd.Series(1, index=X.index, name='bias'), X], axis=1)\n",
    "\n",
    "    identity_matrix = np.identity(X_bias.shape[1])\n",
    "    coefficients = np.linalg.inv(X_bias.T @ X_bias + alpha * identity_matrix) @ X_bias.T @ y\n",
    "    \n",
    "    return coefficients\n",
    "\n",
    "def predict(X, coefficients):\n",
    "    X_bias = pd.concat([pd.Series(1, index=X.index, name='bias'), X], axis=1)\n",
    "    \n",
    "    predictions = X_bias @ coefficients\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def k_fold_cross_validation(df, k, alpha_values, target_column='popularity', stop_condition=None):\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    fold_size = len(X) // k\n",
    "    errors = []\n",
    "\n",
    "    for alpha in alpha_values:\n",
    "        alpha_errors = []\n",
    "        for i in range(k):\n",
    "            start, end = i * fold_size, (i + 1) * fold_size\n",
    "\n",
    "            # Split the data into training and validation sets\n",
    "            X_train = pd.concat([X.iloc[:start], X.iloc[end:]])\n",
    "            y_train = pd.concat([y.iloc[:start], y.iloc[end:]])\n",
    "            X_val = X.iloc[start:end]\n",
    "            y_val = y.iloc[start:end]\n",
    "\n",
    "            # Train ridge regression model\n",
    "            coefficients = ridge_regression(X_train, y_train, alpha)\n",
    "\n",
    "            # Make predictions on the validation set\n",
    "            predictions = predict(X_val, coefficients)\n",
    "\n",
    "            # Calculate mean squared error\n",
    "            mse = mean_squared_error(y_val, predictions)\n",
    "            alpha_errors.append(mse)\n",
    "\n",
    "            # Check the stop condition\n",
    "            if stop_condition is not None and stop_condition(y_val):\n",
    "                break\n",
    "\n",
    "        # Average the errors across folds for the current alpha\n",
    "        errors.append(np.mean(alpha_errors))\n",
    "\n",
    "        # Check the stop condition after each alpha value\n",
    "        if stop_condition is not None and stop_condition(errors):\n",
    "            break\n",
    "\n",
    "    return errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_condition(iteration, max_iterations=1000):\n",
    "    return iteration >= max_iterations\n",
    "\n",
    "def stop_condition2(coefficients, threshold=1e-4):\n",
    "    return all(abs(coef) < threshold for coef in coefficients)\n",
    "\n",
    "def stop_condition3(validation_errors, threshold=1e-4):\n",
    "    return any(error > threshold for error in validation_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "shuffled_df = df.sample(frac=1, random_state=42)\n",
    "train_percentage = 0.7\n",
    "\n",
    "train_size = int(len(shuffled_df) * train_percentage)\n",
    "\n",
    "df_train = shuffled_df.iloc[:train_size]\n",
    "df_test = shuffled_df.iloc[train_size:]\n",
    "\n",
    "alpha_values = [0.1, 1.0, 10.0]\n",
    "k_fold = 5\n",
    "\n",
    "errors = k_fold_cross_validation(df_train, k_fold, alpha_values, stop_condition=stop_condition3)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the alpha with the lowest mean squared error\n",
    "best_alpha = alpha_values[np.argmin(errors)]\n",
    "print(\"Best alpha:\", best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best alpha using the entire training set\n",
    "final_coefficients = ridge_regression(df_train.drop(columns=['popularity']), df_train['popularity'], best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_predictions = predict(df_test.drop(columns=['popularity']), final_coefficients)\n",
    "test_mse = mean_squared_error(df_test['popularity'], test_predictions)\n",
    "print(\"Test Mean Squared Error:\", test_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
